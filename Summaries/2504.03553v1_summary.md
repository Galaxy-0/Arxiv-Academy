```markdown
# 论文总结：Agentic Knowledgeable Self-awareness

## 1. 核心问题
- **背景**：现有LLM智能体规划方法采用"大水漫灌"策略， indiscriminately注入黄金轨迹、外部反馈和领域知识，忽视了人类决策中**情境化自我认知**（动态评估需求并策略性调用资源）的关键机制。
- **问题提出**：如何让LLM智能体像人类一样具备**知识性自我认知能力**（动态判断是否需要调用知识）？

## 2. 方法创新：KnowSelf框架
### 2.1 核心思想
- 定义三种决策情境：
  - **快速思考**：能直接生成正确动作
  - **慢速思考**：需多次反思后生成正确动作
  - **知识性思考**：必须依赖外部知识才能生成正确动作

### 2.2 关键技术
1. **数据构建**：
   - 通过启发式标准（表1）标注智能体自探索轨迹中的情境类型
   - 使用特殊标记（`<r>`, `<k>`）区分不同情境

2. **两阶段训练**：
   - **阶段1**：监督微调（SFT）建立基础自我认知模式
   - **阶段2**：RPO损失函数（DPO + 标准化SFT）增强自我认知能力

3. **推理机制**：
   - 通过生成特殊标记动态切换决策模式
   - 知识调用率（Know%）仅需15-26%即可达到最优效果

## 3. 实验结果
### 3.1 基准测试
| 模型       | ALFWorld (成功率) | WebShop (奖励) | 知识调用率 |
|------------|------------------|----------------|-----------|
| GPT-4o     | 85.07            | 67.40          | 0%        |
| Llama-8B   | **84.33**        | **67.14**      | 15.01%    |
| Gemma-2B   | 79.85            | 63.65          | 26.41%    |

### 3.2 关键发现
1. **性能优势**：
   - 在Llama-8B上超越GPT-4o的Reflexion方法
   - 仅需15-26%的知识调用即可超越全知识基线

2. **泛化能力**（图3b）：
   - 在未见任务上表现优于传统方法5-10倍
   - 打破轨迹模仿导致的模式固化问题

3. **扩展规律**（图3c）：
   - 模型性能随参数规模和数据量增长而提升
   - 自我认知数据占比需>40%才能显现效果

## 4. 机制分析
- **层级激活模式**（图4）：
  - 知识调用决策仅发生在Transformer最后几层
  - 动作生成与知识需求判断存在"博弈"过程
- **消融实验**（图3a）：
  - 纯反思（w/o know）优于纯知识（w/o ret）
  - 全知识注入（w/ full know）会损害小模型性能

## 5. 贡献与启示
1. **理论贡献**：
   - 首次提出"知识性自我认知"的智能体范式
   - 建立情境分类的量化标准

2. **实践价值**：
   - 证明选择性知识调用可降低85%的推理成本
   - 为构建高效能认知智能体提供新范式

3. **未来方向**：
   - 探索更细粒度的情境划分标准
   - 研究自我认知能力的涌现阈值

> 注：所有实验均基于ALFWorld和WebShop数据集，代码已开源（https://github.com/zjunlp/KnowSelf）
``` 

该总结严格遵循原文结构，保留了所有关键数据（包括表格和图示引用），同时突出了方法创新性和实验发现的显著性。Markdown格式便于快速浏览核心内容，层级标题清晰呈现论文逻辑脉络。